{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN - openpose.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "443UO6bck1bY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpR-bwECk1Tc",
        "colab_type": "code",
        "outputId": "b2793b86-6604-42a9-874c-bb6935f95e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "tf.executing_eagerly()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgrbgtPWkqEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf  \n",
        "from sklearn import metrics\n",
        "import random\n",
        "from random import randint\n",
        "import time\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r7UrsdYd7hL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABELS = [\"WALKING\", \"NON_WALKING\"]  \n",
        "X_train_path = \"X_train.txt\"\n",
        "X_test_path = \"X_test.txt\"\n",
        "y_train_path = \"Y_train.txt\"\n",
        "y_test_path = \"Y_test.txt\"\n",
        "n_steps = 20 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3zKkMvWeKam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_X(X_path):\n",
        "    file = open(X_path, 'r')\n",
        "    X_ = np.array([elem for elem in [row.split(',') for row in file]], dtype=np.float32)\n",
        "    file.close()\n",
        "    blocks = int(len(X_) / n_steps)\n",
        "    X_ = np.array(np.split(X_,blocks))\n",
        "    return X_ \n",
        "\n",
        "def load_y(y_path):\n",
        "    file = open(y_path, 'r')\n",
        "    y_ = np.array(\n",
        "        [elem for elem in [row.replace('  ', ' ').strip().split(' ') for row in file]], dtype=str)\n",
        "    file.close()\n",
        "    score = []\n",
        "    for i in range(y_.shape[0]):\n",
        "      if y_[i][0] == \"not_walking\":\n",
        "        score.append(0.0)\n",
        "      else:\n",
        "        score.append(1.0)\n",
        "    score = np.asarray(score)\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIEJc-gKeNmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = load_X(X_train_path)\n",
        "X_test = load_X(X_test_path)\n",
        "\n",
        "y_train = load_y(y_train_path)\n",
        "y_test = load_y(y_test_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaPcwAL45Dj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = y_train.tolist()\n",
        "temp = temp[:-40]\n",
        "y_train = np.asarray(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liQkW2O15Bym",
        "colab_type": "code",
        "outputId": "4c223c30-2c4b-4ac6-de90-3fad54817077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26860, 20, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEKQJuY-fwYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data_count = len(X_train)  \n",
        "test_data_count = len(X_test)  \n",
        "n_input = len(X_train[0][0])  \n",
        "\n",
        "n_hidden = 34 \n",
        "n_classes = 6 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8tZBWx8gAGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decaying_learning_rate = True\n",
        "learning_rate = 0.0025 \n",
        "init_learning_rate = 0.005\n",
        "decay_rate = 0.96 \n",
        "decay_steps = 100000 \n",
        "global_step = tf.Variable(0, trainable=False)\n",
        "lambda_loss_amount = 0.0015\n",
        "training_iters = training_data_count *300  \n",
        "batch_size = 512\n",
        "display_iter = batch_size*8  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrxNgdRAgA3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTM_RNN(_X, _weights, _biases):\n",
        "    _X = tf.transpose(_X, [1, 0, 2]) \n",
        "    _X = tf.reshape(_X, [-1, n_input])   \n",
        "    _X = tf.nn.relu(tf.matmul(_X, _weights['hidden']) + _biases['hidden'])\n",
        "    _X = tf.split(_X, n_steps, 0) \n",
        "\n",
        "    lstm_cell_1 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
        "    lstm_cell_2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
        "    lstm_cells = tf.nn.rnn_cell.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
        "    outputs, states = tf.nn.static_rnn(lstm_cells, _X, dtype=tf.float32)\n",
        "    lstm_last_output = outputs[-1]\n",
        "    return tf.matmul(lstm_last_output, _weights['out']) + _biases['out']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEwjsXsGgcnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_batch_size(_train, _labels, _unsampled, batch_size):\n",
        "    shape = list(_train.shape)\n",
        "    shape[0] = batch_size\n",
        "    batch_s = np.empty(shape)\n",
        "    batch_labels = np.empty((batch_size,1)) \n",
        "\n",
        "    for i in range(batch_size):\n",
        "        index = random.choice(_unsampled)\n",
        "        batch_s[i] = _train[index] \n",
        "        batch_labels[i] = _labels[index]\n",
        "        _unsampled = [i for i in range(_train.shape[0]) if i != index]\n",
        "    return batch_s, batch_labels, _unsampled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84FzBI0XgroH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(y_):\n",
        "    y_ = y_.reshape(len(y_))\n",
        "    n_values = int(np.max(y_)) + 1\n",
        "    return np.eye(n_values)[np.array(y_, dtype=np.int32)] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BSz9JjSgyLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, [None, n_steps, n_input])\n",
        "y = tf.placeholder(tf.float32, [None, n_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9ZSFIuXg0nO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = {\n",
        "    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])),\n",
        "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes], mean=1.0))\n",
        "}\n",
        "biases = {\n",
        "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
        "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR7olNw7hLBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = LSTM_RNN(x, weights, biases)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xinFMRWihMrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l2 = lambda_loss_amount * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()) \n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)) + l2 \n",
        "if decaying_learning_rate:\n",
        "    learning_rate = tf.train.exponential_decay(init_learning_rate, global_step*batch_size, decay_steps, decay_rate, staircase=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoI6z3W8jgDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I9zid2gj12u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTbZ_acJpPil",
        "colab_type": "code",
        "outputId": "04ad7312-092d-4ded-b862-f2cb980ce4b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "test_losses = []\n",
        "test_accuracies = []\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhlFHskkpR2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "step = 1\n",
        "time_start = time.time()\n",
        "unsampled_indices = range(0,len(X_train))\n",
        "\n",
        "while step * batch_size <= training_iters:\n",
        "    if len(unsampled_indices) < batch_size:\n",
        "        unsampled_indices = range(0,len(X_train)) \n",
        "    batch_xs, raw_labels, unsampled_indicies = extract_batch_size(X_train, y_train, unsampled_indices, batch_size)\n",
        "    batch_ys = one_hot(raw_labels)\n",
        "    if len(batch_ys[0]) < n_classes:\n",
        "        temp_ys = np.zeros((batch_size, n_classes))\n",
        "        temp_ys[:batch_ys.shape[0],:batch_ys.shape[1]] = batch_ys\n",
        "        batch_ys = temp_ys\n",
        "       \n",
        "    _, loss, acc = sess.run(\n",
        "        [optimizer, cost, accuracy],\n",
        "        feed_dict={x: batch_xs, y: batch_ys} )\n",
        "    train_losses.append(loss)\n",
        "    train_accuracies.append(acc)\n",
        "    if (step*batch_size % display_iter == 0) or (step == 1) or (step * batch_size > training_iters):\n",
        "        print(\"Iter #\" + str(step*batch_size) + \\\n",
        "              \":  Learning rate = \" + \"{:.6f}\".format(sess.run(learning_rate)) + \\\n",
        "              \":   Batch Loss = \" + \"{:.6f}\".format(loss) + \\\n",
        "              \", Accuracy = {}\".format(acc))\n",
        "        \n",
        "        # Evaluation on the test set (no learning made here - just evaluation for diagnosis)\n",
        "        loss, acc = sess.run(\n",
        "            [cost, accuracy], \n",
        "            feed_dict={\n",
        "                x: X_test,\n",
        "                y: one_hot(y_test)\n",
        "            }\n",
        "        )\n",
        "        test_losses.append(loss)\n",
        "        test_accuracies.append(acc)\n",
        "        print(\"PERFORMANCE ON TEST SET:             \" + \\\n",
        "              \"Batch Loss = {}\".format(loss) + \\\n",
        "              \", Accuracy = {}\".format(acc))\n",
        "\n",
        "    step += 1\n",
        "\n",
        "print(\"Optimization Finished!\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}